{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTL Sat Transformer Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml2.ltl.ltl_sat.ltl_sat_transformer_experiment import LTLSatTransformerExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml2.artifact:Found experiment t-13 locally\n",
      "INFO:ml2.experiment:Initialized experiment with arguments:\n",
      "alpha: 0.5\n",
      "aps: ['a', 'b', 'c', 'd', 'e']\n",
      "batch_size: 256\n",
      "beam_size: 1\n",
      "cache_dataset: True\n",
      "checkpoint_monitor: val_accuracy_per_sequence\n",
      "custom_pos_enc: True\n",
      "d_embed_dec: 256\n",
      "d_embed_enc: 256\n",
      "d_ff: 1024\n",
      "dataset_name: rft-0\n",
      "drop_batch_remainder: True\n",
      "dropout: 0.0\n",
      "dtype_float: <dtype: 'float32'>\n",
      "dtype_int: <dtype: 'int32'>\n",
      "ff_activation: relu\n",
      "group: None\n",
      "initial_steps: 0\n",
      "max_input_length: 128\n",
      "max_target_length: 128\n",
      "name: t-13\n",
      "num_heads: 4\n",
      "num_layers_dec: 6\n",
      "num_layers_enc: 6\n",
      "parent_name: \n",
      "shuffle_on_load: True\n",
      "steps: 30000\n",
      "stream_to_wandb: False\n",
      "tf_shuffle_buffer_size: 0\n",
      "val_freq: 100\n",
      "wandb_run_id: None\n",
      "warmup_steps: 4000\n",
      "WARNING:ml2.experiment:Experiment t-13 already exists locally\n"
     ]
    }
   ],
   "source": [
    "experiment = LTLSatTransformerExperiment.load('t-13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Constructed vocabulary containing 11 tokens\n",
      "INFO:ml2.seq2seq_experiment:Initialized input encoder\n",
      "2022-02-01 16:25:32.095289: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:root:Constructed vocabulary containing 15 tokens\n",
      "INFO:ml2.seq2seq_experiment:Initialized target encoder\n",
      "INFO:ml2.experiment:Created evaluation model\n",
      "INFO:ml2.experiment:Found checkpoint /Users/Frederik/ml2-storage/ltl-sat/t-13/checkpoint\n",
      "INFO:ml2.experiment:Loaded weights from checkpoint\n",
      "INFO:ml2.tools.containerized_grpc_service:Spot container quizzical_archimedes on port 50051 is running\n",
      "INFO:ml2.tools.containerized_grpc_service:Successfully connected to Spot gRPC server running in container quizzical_archimedes on port 50051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'trace': 'b ; { 1 }',\n",
       "  'verification': <TraceMCStatus.SATISFIED: 'satisfied'>}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.call('a U b', training=False, verify=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8caa4319d59a734f94e739df6b594acde678ec5f2e3eb7152d087fc4a1992669"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('ml2': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "6777b983a30343457facb6d641fab749a3d1ac686971770ba4e1636635b77c7f"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
